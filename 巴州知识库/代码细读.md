
  后端流程：
1. 调用外部解析服务（file_parse_url）
2. 调用 update_docs() 进行向量化
3. 删除旧的分块记录
4. 保存新的分块记录
5. 更新文档状态为已向量化


## oss.py
基于本地文件系统实现的简单对象存储系统，提供了：
	内存缓存cache
	内存临时存储ram
	本地文件系统持久化
	（后台线程)异步写入
	线程安全保护
	自动缓存清理
核心业务流程：
	Upload → 缓存cache →（可选）加入保存队列（写入本地文件系统） → 后台线程保存 → 自动清理缓存；
	Download → 内存（ram） → 缓存（cache） → 磁盘 → 写入缓存
**锁的使用**：
	1. cache 使用了threading.Lock()
		- 保护范围
			- self.cache
			- self.cached_size
			- 缓存清理逻辑
	2. ram 也使用了threading.Lock()
		- 保护范围
			- self.ram
	3. `with` 会自动 acquire 和 release
```python
# 上下文管理器自动调用self.lck.acquire()
# 执行代码块
# 无论是否正常结束，都自动调用self.lck.release()
with self.lck:
    ...代码块
    
# 等价于
self.lck.acquire()
try:
    ...代码块
finally:
    self.lck.release()
```

线程的使用：
	1. 创建一个普通线程，作为后台线程。 ^d400fc
```python
self.save_thr = threading.Thread(target=self.loop_save)  
self.save_thr.start()
```
	2.这个线程一直执行loop_save函数，专门负责处理保存任务。
```python
def loop_save(self):
    while True:
	    代码块
```


# kbase 与 chatchat 的连接
- kbase_dms：文档管理系统，负责文件上传、管理、向量化
	- app.sqs.com服务器中/home/user/DiMS-DAPP/docker_home/kbase_dms
	- 流程：
		1. 用户上传文档（PDF、Word等）
		2. 系统将文档转换为PDF并存储到OSS
		3. 后台将文档切分、向量化，存入知识库
		4. 文档元数据存入MySQL数据库


- Langchain-Chatchat：对话系统，提供知识库对话功能
	- sqs@192.168.124.221 password 路径：/mnt/hs-ssd/vllms/Langchain-Chatchat
	- 功能：基于知识库的智能对话
	- 流程：
		1. 用户提问
		2. 系统将问题向量化，在知识库中搜索相关文档片段
		3. 将相关文档作为上下文，调用LLM生成回答
连接：
- 共享知识库存储路径：两个系统使用同一个向量库目录
- 共享向量数据：kbase_dms 创建的向量，chatchat 可以直接使用


现状：
	- 知识库查询文件的路径是：/mnt/hs-ssd/vllms/Langchain-Chatchat/knowledge_base/{知识库名称}/content/
	- 现在的对话系统中，知识库的名称是BZGZ0925，从而推断现在的对话系统在哪里搜索文件。
	- 
- 向量索引存储在 kbase_dms 的知识库目录：
	~/DiMS-DAPP/docker_home/kbase_dms/knowledge_base/{知识库ID}/vector_store/bge-large-zh-v1.5/
	├── index.faiss
	└── index.pkl




kbase提供的接口：  【补充：后续这两个接口都没用上，写得新的接口】
- /bus/files/search - 业务搜索接口
	- kbase_dms\api\files_kbase.py中@files_kbase.route("/search", methods="GET")
	- 根据关键词搜索文件，支持向量搜索和文件名搜索。
	- 返回数据：
		- 文件信息列表（==DbDocument== 记录）
		- 包含：id, name, kbase_id, is_file, is_active, pdf_path 等。 
		- 不包含：文本块的具体内容
- /restful/document_doc - 文本块 CRUD 接口
	- 对文本块进行增删改查，直接操作数据库表 document_to_doc。
	- 返回数据：
		- 文本块信息（==DbDocumentToDoc== 记录）
		- 包含：id, file_id, kbase_id, doc_id, content（文本内容）, meta_data（JSON字符串）, embedding, create_time
		- 直接返回文本块内容
```python
	# 1. 接收参数（通过查询参数或请求体）
	params = {
	    "id": "文本块ID",           # 可选：获取单个文本块
	    "file_id": "文件ID",        # 可选：获取某个文件的所有文本块
	    "kbase_id": "知识库ID",     # 可选：获取某个知识库的所有文本块
	    "doc_id": "向量库ID",       # 可选：根据向量库ID查找
	    "page": 1                   # 可选：分页
	}
	# 2. 通过 accessor 查询数据库
	if "id" in params:
	    # 获取单个文本块
	    chunk = kbase_document_to_doc_accessor[id]
	    return chunk  # 返回单个对象
	else:
	    # 获取列表（支持过滤）
	    chunks = kbase_document_to_doc_accessor.get_all(**params)
    return chunks  # 返回列表
```


kabse中接口的使用方法：
```python
    # 第一步：使用 /bus/files/search 找到相关文件
		GET /bus/files/search?key_words=人工智能&kbase_names=kb1&search_doc=1
		# 返回的数据示例
		[
		    {
		        "id": "file_123",              // ← 这就是 file_id！
		        "kbase_id": 1,
		        "name": "AI技术文档.pdf",
		        "is_file": 1,
		        "is_active": 1,
		        "pdf_path": "/path/to/file.pdf",
		        "oss_path": "/path/to/file.pdf",
		        "level": 1,
		        "parent": "parent_id",
		        "file_path": "/path/to/file",
		        "is_convert_pdf": 1,
		        "create_time": "2024-01-01 10:00:00",
		        // ... 其他所有字段
		    },
		    {}
		  ]
		
		# 第二步：使用 /restful/document_doc 获取这些文件的文本块内容
		for file_id in files:
		    chunks = GET /restful/document_doc?file_id=file_id
		    # 返回：该文件的所有文本块，包含实际内容
		
		    # 将这些文本块用于对话上下文
		    for chunk in chunks:
		        context += chunk['content']  # 使用文本内容
		
		# 返回的数据示例
		[
		    {
		        "id": "chunk_001",
		        "file_id": "file_123",
		        "kbase_id": 1,
		        "doc_id": "doc_001",
		        "content": "人工智能是计算机科学的一个分支...",  # 实际文本内容
		        "meta_data": "{\"pageidx\": 1, \"source\": \"AI技术文档.pdf\"}",
		        "create_time": "2024-01-01 10:00:00"
		    },
		    {
		        "id": "chunk_002",
		        "file_id": "file_123",
		        "content": "机器学习是人工智能的核心技术...",
		        ...
		    },
		    ...
		]
		# 注意：这里返回的是文本块，包含实际的内容
```




chatchat中：
- server/knowledge_base/kb_service/faiss_kb_service.py:61-79 
- do_serach（）
	-   返回搜索结果
	- docs: List[Tuple[Document, float]]
	- Document: langchain.docstore.document.Document
	- float: 相似度分数
		- 返回的是一个列表，列表中每个元素是一个元组，元组中第一个元素是Document对象，第二个元素是相似度分数

        例如：
         [(Document1, 0.9), (Document2, 0.8), (Document3, 0.7)]
        其中，Document1, Document2, Document3 是搜索到的文档，0.9, 0.8, 0.7 是相似度分数

         Document 对象包含：
	         page_content: 文本内容
	         metadata: 元数据（包含 source 文件名等）


## 实际操作
kbase：
- 创建一个接口，搜索文件并返回chat需要的
	- /home/user/DiMS-DAPP/docker_home/kbase_dms/api/files_kbase.py中添加接口
- studio中停止后重启
- 测试接口：curl "http://localhost:9601/bus/files/search_chunks?key_words=test&kbase_names=kb1&top_k=5"
- 在221服务器上测试：curl "http://192.168.127.8:9601/bus/files/search_chunks?key_words=test&kbase_names=kb1&top_k=5"


chatchat:
	
	用户输入问题
	    ↓
	前端调用 /chat/knowledge_base_chat API
	    ↓
	传入 knowledge_base_name = "你的kbase_id"
	    ↓
	KBServiceFactory.get_service_by_name("你的kbase_id")
	    ↓ (从数据库读取 vs_type = "kbase")
	创建 KbaseKBService 实例
	    ↓
	调用 search_docs()
	    ↓
	GET http://app.sqs.com:9601/bus/files/search_chunks
	    ↓
	返回匹配的文档，用于生成回答
### 在 chatchat 数据库中注册知识库，并设置 vs_type 为 'kbase'

#### 第一步：创建知识库
- 知识库名称必须与 Kbase 系统中的 kbase_id 完全一致

- 如何查看 Kbase 系统中的 kbase_id ：
	- 在sqs测试curl -G "http://localhost:9601/bus/files/search_chunks"   --data-urlencode "key_words=防火墙策略"   --data-urlencode "kbase_names=2"   --data-urlencode "top_k=10"
	- 当kbase_names=2的时候能输出东西，应该是说明现在用的文件系统对应的知识库就是kbase_name =2

- 创建知识库代码：
```bash
curl -X POST "http://localhost:7861/knowledge_base/create_knowledge_base"   -H "Content-Type: application/json"   -d '{
    "knowledge_base_name": "2",
    "vector_store_type": "kbase",
    "embed_model": "bge-large-zh-v1.5"
  }'
{"code":200,"msg":"已新增知识库 2","data":null}
```

- chatchat：http://192.168.124.221:8501/
- kbase: http://192.168.127.8:9601/bus/files/search_chunks?key_words=test&kbase_names=kb1&top_k=5


#### 第二步：

>是中文编码的问题⬇️
>
>在浏览器中打开chatcaht后搜索，kbase中的日志长这样：
>
>search_chunks: 防火墙策略申请 ['2'] 3 0.35
>search_docs_from_multi_kbase: 2 @ bge-large-zh-v1.5 ['2']
>使用本地Embeddings模型: base_url='http://192.168.124.221:11434' model='quentinz/bge-large-zh-v1.5:latest' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False model_kwargs=None bge-large-zh-v1.5
>
>do_search result: 0.35 []
>search_chunks result count: 0
>kbase_core> 2025-12-04 19:33:20,218 INFO: 192.168.124.221 - - [04/Dec/2025 19:33:20] "GET /bus/files/search_chunks?key_words=防火墙策略申请&kbase_names=2&top_k=3&score_threshold=0.35 HTTP/1.1" 200 -
>
>而在chatchat服务器的终端执行
	 curl -G "http://192.168.127.8:9601/bus/files/search_chunks" --data-urlencode "key_words=防火墙策略" --data-urlencode "kbase_names=2" --data-urlencode "top_k=10"，
却能在kbase的日志中看到
	'pageidx': 0, 'partition_pageidx': {'0': 1001, '1': 1794, '2': 1842}, 'source': 'eaef23ca-fc9f-42c9-80c1-5dbb419156e1', 'id': 'e49b61ac-09ba-44da-99f3-aa334d56e944'}), 0.79011595)]
	search_chunks result count: 1
	kbase_core> 2025-12-04 19:36:47,220 INFO: 192.168.124.221 - - [04/Dec/2025 19:36:47] "GET /bus/files/search_chunks?key_words=防火墙策略&kbase_names=2&top_k=10 HTTP/1.1" 200 -



>中文编码已经修复，kbase服务器能够正确解析。 ⬇️
>但是现在kbase返回的分数是0.93910444，chatchat阈值设置的1.0，可能被过滤了
>
> 'pageidx': 0, 'partition_pageidx': {'0': 1001, '1': 1794, '2': 1842}, 'source': 'eaef23ca-fc9f-42c9-80c1-5dbb419156e1', 'id': 'e49b61ac-09ba-44da-99f3-aa334d56e944'}), 0.93910444)]
search_chunks result count: 1
kbase_core> 2025-12-05 10:27:59,098 INFO: 192.168.124.221 - - [05/Dec/2025 10:27:59] "GET /bus/files/search_chunks?key_words=防火墙&kbase_names=2&top_k=3&score_threshold=1.0 HTTP/1.1" 200 -

>chatchat中分数阈值设置为更低的0.39后反而没有返回结果了⬇️
>
>search_docs_from_multi_kbase: 2 @ bge-large-zh-v1.5 ['2']
>do_search result: 0.39 []
>search_chunks result count: 0
kbase_core> 2025-12-05 10:45:43,865 INFO: 192.168.124.221 - - [05/Dec/2025 10:45:43] "GET /bus/files/search_chunks?key_words=防火墙&kbase_names=2&top_k=3&score_threshold=0.39 HTTP/1.1" 200 -

  

>问题1：kbase中的score是距离，距离越小表示相似度越高，只返回 score <= score_threshold 的结果。而在chatchat中score是相似度，越小表示相似度越低。所以会出现调低chatcaht中的分数阈值，反而kbase中不再返回内容的情况。
>问题2：kbase提供的接口/bus/files/search_chunks的返回结果已按 score_threshold 过滤：只返回 score <= score_threshold 的文档
>
>修改：
>1. 排序改为升序（reverse=False），因为距离越小越好
>2. 移除客户端过滤，因为服务器端已按 score_threshold 过滤
>
>新问题：当前逻辑不符合直觉
>	用户期望（相似度阈值）：
>	- 阈值越高 → 更严格 → 返回更少但更相关的结果
>	- 阈值越低 → 更宽松 → 返回更多结果
>解决方案：在客户端将“相似度阈值”转换为“距离阈值”后再传给 kbase。


  
>chatchat的两个端口
>1. 8501 是硬编码知识库（webui_lite.py → dialogue_lite.py）
>	1. /mnt/hs-ssd/vllms/Langchain-Chatchat/webui_pages/dialogue/dialogue_lite.py
>	2. on_kb_change()函数中可以修改知识库、阈值等
>2. 8502有知识库选择UI （webui.py + lite 参数 → dialogue.py）
>	1. 思考和知识库还有问题，不会输出
>	
>目前DimS-DAPP采用8501


>chatchat知识库匹配结果的输出不是文件名，而是uuid。
>
>思考：
>kbase中/search_chunks接口的返回数据结构
>{
  // 文本块信息
  "chunk_id": "string",        // 文本块ID（document_to_doc.id）
  "doc_id": "string",          // 向量库ID（document_to_doc.doc_id）
  "content": "string",          // 文本内容
  "score": float,               // 相似度分数（距离值，越小越相似）
  // 文件信息
  "file_id": "string" | null,   // 文件ID（如果找不到文件则为 null）
  "file_name": "string",        // 文件名称（如果找不到文件则为空字符串 ""）
  "kbase_id": int | null,      // 知识库ID（如果找不到文件则为 null）
  // 元数据
  "metadata": {                 // 完整元数据对象
    "id": "string",            // 向量库ID（与 doc_id 相同）
    "source": "string",         // 文件路径（相对路径）
    "pageidx": int,            // 页码索引（如果存在）
    // ... 其他可能的元数据字段
	  }
 }
经过print kbase中该接口的返回值可以看到，file_name字段就是空的。
>
思路：kbase中/search_chunks接口的逻辑是
>- 先在本地搜索得到文件块信息，再去数据库中搜索得到文件信息（文件名、文件id等）
>- 之前使用doc.metadata.get('source', '')在数据库中搜索，而source是一个类似 UUID 的字符串，而不是文件路径或文件名。所以搜索不到。
>
>解决方法：metadata["source"] 实际上就是 DbDocument.id，那 /search_chunks 这里就应该按 id 查，而不是按 pdf_path 查。就可以查到
>现在输出的file_name就是文件名。
>

>知识库匹配结果的链接点不开：
>传递pdf_path
>使用("/pdf/<path:uri>", methods=["GET"])def get_pdf(uri) 文件访问接口





