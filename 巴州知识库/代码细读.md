
  后端流程：
1. 调用外部解析服务（file_parse_url）
2. 调用 update_docs() 进行向量化
3. 删除旧的分块记录
4. 保存新的分块记录
5. 更新文档状态为已向量化


## oss.py
基于本地文件系统实现的简单对象存储系统，提供了：
	内存缓存cache
	内存临时存储ram
	本地文件系统持久化
	（后台线程)异步写入
	线程安全保护
	自动缓存清理
核心业务流程：
	Upload → 缓存cache →（可选）加入保存队列（写入本地文件系统） → 后台线程保存 → 自动清理缓存；
	Download → 内存（ram） → 缓存（cache） → 磁盘 → 写入缓存
**锁的使用**：
	1. cache 使用了threading.Lock()
		- 保护范围
			- self.cache
			- self.cached_size
			- 缓存清理逻辑
	2. ram 也使用了threading.Lock()
		- 保护范围
			- self.ram
	3. `with` 会自动 acquire 和 release
```python
# 上下文管理器自动调用self.lck.acquire()
# 执行代码块
# 无论是否正常结束，都自动调用self.lck.release()
with self.lck:
    ...代码块
    
# 等价于
self.lck.acquire()
try:
    ...代码块
finally:
    self.lck.release()
```

线程的使用：
	1. 创建一个普通线程，作为后台线程。 ^d400fc
```python
self.save_thr = threading.Thread(target=self.loop_save)  
self.save_thr.start()
```
	2.这个线程一直执行loop_save函数，专门负责处理保存任务。
```python
def loop_save(self):
    while True:
	    代码块
```


# kbase 与 chatchat 的连接
- kbase_dms：文档管理系统，负责文件上传、管理、向量化
	- 流程：
		1. 用户上传文档（PDF、Word等）
		2. 系统将文档转换为PDF并存储到OSS
		3. 后台将文档切分、向量化，存入知识库
		4. 文档元数据存入MySQL数据库

- Langchain-Chatchat：对话系统，提供知识库对话功能
	- 功能：基于知识库的智能对话
	- 流程：
		1. 用户提问
		2. 系统将问题向量化，在知识库中搜索相关文档片段
		3. 将相关文档作为上下文，调用LLM生成回答
连接：
- 共享知识库存储路径：两个系统使用同一个向量库目录
- 共享向量数据：kbase_dms 创建的向量，chatchat 可以直接使用