# ollama模型部署
1. 用处：api_base_url = 'http://192.168.124.223:11434'  # ollama部署的文档解析embedding模型；
2. 部署流程：
	1. 登录221服务器：sqs @192.168.124.221 password
	2. Ollam的镜像就在路径：/mnt/hs-ssd/vllms/jisuan_backend
	3. 创建容器并启动：ocker run -it --name ollama --gpus all --net host -v /mnt/hs-ssd/vllms/:/mnt/hs-ssd/vllms -v /mnt/hs-ssd/vllms/ollama:/root/.ollama ollama/ollama:0.9.6
	4. 测试
		1. curl http://localhost:11434/api/tags 生成模型列表
		2. curl http://localhost:11434/api/version 查看版本


# chatchat 部署
sqs@192.168.124.221 password
路径：/mnt/hs-ssd/vllms/Langchain-Chatchat
启动容器：
	docker run -it --name chatchat-new-v1-auto --restart=always --gpus all --net host -v /mnt/hs-ssd/vllms:/mnt/hs-ssd/vllms --shm-size=256g chatchat:latest /mnt/hs-ssd/vllms/Langchain-Chatchat/start_chat.sh
停止：
	docker stop chatchat-new-v1-auto 
重新启动：
	docker restart chatchat-new-v1-auto 
对话功能端口：           http://192.168.124.221:8501/
完整知识库功能端口：Port 8502 is already in use，端口被占用【不用管】

---
向量库加载：
路径：/mnt/hs-ssd/vllms/Langchain-Chatchat/server/knowledge_base/kb_cache.base.py
修改其中的：
```python
from langchain.embeddings.ollama import OllamaEmbeddings
embeddings = OllamaEmbeddings(base_url='http://192.168.124.221:11434', model="quentinz/bge-large-zh-v1.5:latest")
```
其中的模型名可以通过在221服务器上运行curl http://localhost:11434/api/tags 得到模型列表。

---
路径：/mnt/hs-ssd/vllms/Langchain-Chatchat/configs下修改配置
其中model_config.py中配置ollama的接口路径





# DiMS-DAPP部署
app.sqs.com服务器中/home/user/repo/DiMS-DAPP-Tracker路径下：
- 修改config.py文件
- 重启DiMs-DAPP服务，sudo systemctl restart dims-dapp-tracker.service
		


# kbase_dms后端
app.sqs.com服务器中/home/user/DiMS-DAPP/docker_home/kbase_dms路径下
- config.py文件修改接口
- 修改了代码需要重新构建镜像
镜像：
	- docker ps 中
	-  kbase_db_backend:3.12.3
	- 
